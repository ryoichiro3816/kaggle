{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, ParameterGrid, cross_validate, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import optuna\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "cat0      0\n",
       "cat1      0\n",
       "cat2      0\n",
       "cat3      0\n",
       "cat4      0\n",
       "cat5      0\n",
       "cat6      0\n",
       "cat7      0\n",
       "cat8      0\n",
       "cat9      0\n",
       "cont0     0\n",
       "cont1     0\n",
       "cont2     0\n",
       "cont3     0\n",
       "cont4     0\n",
       "cont5     0\n",
       "cont6     0\n",
       "cont7     0\n",
       "cont8     0\n",
       "cont9     0\n",
       "cont10    0\n",
       "cont11    0\n",
       "cont12    0\n",
       "cont13    0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          int64\n",
       "cat0       object\n",
       "cat1       object\n",
       "cat2       object\n",
       "cat3       object\n",
       "cat4       object\n",
       "cat5       object\n",
       "cat6       object\n",
       "cat7       object\n",
       "cat8       object\n",
       "cat9       object\n",
       "cont0     float64\n",
       "cont1     float64\n",
       "cont2     float64\n",
       "cont3     float64\n",
       "cont4     float64\n",
       "cont5     float64\n",
       "cont6     float64\n",
       "cont7     float64\n",
       "cont8     float64\n",
       "cont9     float64\n",
       "cont10    float64\n",
       "cont11    float64\n",
       "cont12    float64\n",
       "cont13    float64\n",
       "target    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encode(df):\n",
    "    le = LabelEncoder() \n",
    "    for column in df.select_dtypes('object'):\n",
    "        le.fit(df[column])\n",
    "        df[column]=le.transform(df[column])\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    for column in df.select_dtypes('float64'):\n",
    "        scaler.fit(df[column].values.reshape(-1,1))\n",
    "        df[column] = scaler.transform(df[column].values.reshape(-1,1))\n",
    "         \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-02-28 07:12:15,990]\u001b[0m A new study created in memory with name: no-name-88baaf3e-e4df-4908-bf1e-4bcf7f0b41df\u001b[0m\n",
      "\u001b[32m[I 2021-02-28 07:23:37,311]\u001b[0m Trial 0 finished with value: 0.8451696003569937 and parameters: {'max_depth': 5, 'learning_rate': 0.0412346755521118}. Best is trial 0 with value: 0.8451696003569937.\u001b[0m\n",
      "\u001b[32m[I 2021-02-28 07:37:31,583]\u001b[0m Trial 1 finished with value: 0.8457216048685808 and parameters: {'max_depth': 6, 'learning_rate': 0.0269893000009116}. Best is trial 0 with value: 0.8451696003569937.\u001b[0m\n",
      "\u001b[32m[I 2021-02-28 07:48:46,341]\u001b[0m Trial 2 finished with value: 0.8447281195337972 and parameters: {'max_depth': 5, 'learning_rate': 0.08528713029565459}. Best is trial 2 with value: 0.8447281195337972.\u001b[0m\n",
      "\u001b[32m[I 2021-02-28 08:07:38,283]\u001b[0m Trial 3 finished with value: 0.8459860747668273 and parameters: {'max_depth': 8, 'learning_rate': 0.02264942072724693}. Best is trial 2 with value: 0.8447281195337972.\u001b[0m\n",
      "\u001b[32m[I 2021-02-28 08:19:01,550]\u001b[0m Trial 4 finished with value: 0.8453431029400417 and parameters: {'max_depth': 5, 'learning_rate': 0.037538789326984304}. Best is trial 2 with value: 0.8447281195337972.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最終トライアル回数:5\n",
      "ベストトライアル:\n",
      "値:0.8447281195337972\n",
      "パラメータ:\n",
      "max_depth:5\n",
      "learning_rate:0.08528713029565459\n"
     ]
    }
   ],
   "source": [
    "#ハイパーパラメーターチューニング＋交差検証\n",
    "\n",
    "def objective(trial):\n",
    "    X_train = df_train.drop('target', axis=1)\n",
    "    y_train = df_train['target']\n",
    "    \n",
    "    X_train = Encode(X_train)\n",
    "    \n",
    "    xgb_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 5, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-2, 1e-1, log=True),\n",
    "        n_estimators=500\n",
    "#         min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "#         colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "#         subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "#         reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "#         reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    \n",
    "    clf = XGBRegressor(**xgb_params)\n",
    "    kf = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "   \n",
    "    def RMSE(y_pred, y_true):\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred,y_true))\n",
    "        \n",
    "        return rmse \n",
    "        \n",
    "    some_funcs ={\n",
    "        'RMSE':make_scorer(RMSE)\n",
    "    }\n",
    "    \n",
    "    scores = cross_validate(clf, X=X_train, y=y_train, cv=kf, scoring=some_funcs)\n",
    "    \n",
    "    return scores['test_RMSE'].mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=5)\n",
    "xgb_params = study.best_params\n",
    "\n",
    "# 実行結果表示\n",
    "print('最終トライアル回数:{}'.format(len(study.trials)))\n",
    "print('ベストトライアル:')\n",
    "trial = study.best_trial\n",
    "print('値:{}'.format(trial.value))\n",
    "print('パラメータ:')\n",
    "for key, value in trial.params.items():\n",
    "    print('{}:{}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('target', axis=1)\n",
    "y_train = df_train['target']\n",
    "X_train = Encode(X_train)\n",
    "X_test = Encode(df_test)\n",
    "\n",
    "clf = XGBRegressor(**xgb_params)\n",
    "clf.fit(X_train, y_train)\n",
    "pred_test = clf.predict(X_test)\n",
    "df_sample = pd.read_csv('sample_submission.csv')\n",
    "df_sample['target'] = pred_test\n",
    "df_sample.to_csv('submmit.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
